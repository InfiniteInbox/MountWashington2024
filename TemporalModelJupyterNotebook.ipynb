{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RDVV_3Uqw9T7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Input, LSTM, GRU, Dense, TimeDistributed, Dropout, BatchNormalization, Add\n",
        "from keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRwJrbduw9T9"
      },
      "outputs": [],
      "source": [
        "#Only at home"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4zMSaJtw9T-"
      },
      "source": [
        "WOrking at home now :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "CzIYG0Wyw9T-",
        "outputId": "ada0b736-f55b-49f1-f601-050a51435e97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "         AR16Temperature  AR23Temperature  AR33Temperature  AR40Temperature  \\\n",
            "0                   25.3             21.1             15.7             12.7   \n",
            "1                   25.2             21.2             15.9             12.7   \n",
            "2                   25.1             21.3             15.9             12.6   \n",
            "3                   25.2             21.4             15.9             12.7   \n",
            "4                   25.2             21.4             15.9             12.6   \n",
            "...                  ...              ...              ...              ...   \n",
            "1049756             34.2             42.0             47.5             48.0   \n",
            "1049757             34.0             42.0             47.7             47.9   \n",
            "1049758             33.6             41.9             48.4             47.8   \n",
            "1049759             33.6             41.6             48.2             47.9   \n",
            "1049760             33.6             41.8             48.1             47.9   \n",
            "\n",
            "         AR53Temperature  station_pressure  relative_humidity  dry_bulb  \n",
            "0                    8.0           805.733                 95       5.1  \n",
            "1                    7.9           805.841                 95       5.1  \n",
            "2                    7.9           805.886                 95       5.1  \n",
            "3                    8.0           805.998                 95       5.1  \n",
            "4                    8.0           805.768                 95       5.1  \n",
            "...                  ...               ...                ...       ...  \n",
            "1049756             42.0           808.805                100      38.5  \n",
            "1049757             42.2           808.798                100      38.4  \n",
            "1049758             41.8           808.893                100      38.4  \n",
            "1049759             41.8           808.736                100      38.4  \n",
            "1049760             41.9           808.769                100      38.4  \n",
            "\n",
            "[1047827 rows x 8 columns]\n",
            "1047827\n"
          ]
        }
      ],
      "source": [
        "#train_data = pd.read_csv(r'C:\\Users\\observer\\Desktop\\Yash Machine Learning Code\\temps and summit pressure frAfr for NN.csv', sep=',')\n",
        "train_data = pd.read_csv(r\"C:\\Users\\yjain\\Desktop\\mtwash\\Final Mt Wash\\combined_summit_temp_pressure_vert_temp_rh_no43_2021-2022.csv\", sep=',')\n",
        "train_data.pop('Unnamed: 0')\n",
        "train_data.pop('date')\n",
        "train_data.dropna(inplace=True)\n",
        "print(train_data)\n",
        "\n",
        "train_data.head()\n",
        "\n",
        "training_array = np.array(train_data, dtype='float')\n",
        "print(len(training_array))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0          1609459200\n",
            "1          1609459260\n",
            "2          1609459320\n",
            "3          1609459380\n",
            "4          1609459440\n",
            "              ...    \n",
            "1049756    1672444560\n",
            "1049757    1672444620\n",
            "1049758    1672444680\n",
            "1049759    1672444740\n",
            "1049760    1672444800\n",
            "Name: timestamp, Length: 1047827, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "train_data = pd.read_csv(r\"C:\\Users\\yjain\\Desktop\\mtwash\\Final Mt Wash\\combined_summit_temp_pressure_vert_temp_rh_no43_2021-2022.csv\", sep=',')\n",
        "train_data.pop('Unnamed: 0')\n",
        "train_data.dropna(inplace=True)\n",
        "\n",
        "# Extract and encode date information\n",
        "train_data['date'] = pd.to_datetime(train_data['date'])\n",
        "train_data['timestamp'] = train_data['date'].astype('int64') // 10**9  # Convert to seconds since epoch\n",
        "print(train_data['timestamp'])\n",
        "train_data['day_of_year'] = train_data['date'].dt.dayofyear\n",
        "train_data['day_sin'] = np.sin(2 * np.pi * train_data['day_of_year'] / 365.25)\n",
        "train_data['day_cos'] = np.cos(2 * np.pi * train_data['day_of_year'] / 365.25)\n",
        "train_data.pop('date')\n",
        "train_data.pop('day_of_year')\n",
        "\n",
        "\n",
        "# Convert to numpy array\n",
        "training_array = np.array(train_data, dtype='float')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "RSlrxttcw9T_"
      },
      "outputs": [],
      "source": [
        "\n",
        "def split_array(arr):\n",
        "    year_split = len(arr) // 2\n",
        "    # Split the array into 4 equal parts\n",
        "    batch_size = year_split // 4\n",
        "    batch11 = arr[:batch_size]\n",
        "    batch21 = arr[batch_size:2*batch_size]\n",
        "    batch31 = arr[2*batch_size:3*batch_size]\n",
        "    batch41 = arr[3*batch_size:4*batch_size]\n",
        "    batch12 = arr[4*batch_size:5*batch_size]\n",
        "    batch22 = arr[5*batch_size:6*batch_size]\n",
        "    batch32 = arr[6*batch_size:7*batch_size]\n",
        "    batch42 = arr[7*batch_size:8*batch_size]\n",
        "    x = []\n",
        "    y = []\n",
        "    trained_random_sample_nums = []\n",
        "    for batch_idx, batch in enumerate([batch11, batch21, batch31, batch41, batch12, batch22, batch32, batch42]):\n",
        "          available_indices = list(range(len(batch)))\n",
        "\n",
        "          while available_indices:  # Continue until there are available indices\n",
        "              random_sample_number = random.choice(available_indices)\n",
        "              trained_random_sample_nums.append(random_sample_number)\n",
        "\n",
        "              # Check if there are enough indices for input and output sequences\n",
        "              if random_sample_number >= 15 and random_sample_number + 15 < len(batch):\n",
        "                  # Select 15 rows before as input sequence\n",
        "                  input_sequence = batch[random_sample_number - 15:random_sample_number]\n",
        "                  # Select 15 rows ahead as output sequence\n",
        "                  output_sequence = batch[random_sample_number: random_sample_number + 15]\n",
        "\n",
        "                  x.append(input_sequence)\n",
        "                  y.append(output_sequence)\n",
        "\n",
        "                  # Remove selected indices and indices of surrounding rows\n",
        "                  indices_to_remove = list(range(random_sample_number - 15, random_sample_number + 15))\n",
        "                  available_indices = [idx for idx in available_indices if idx not in indices_to_remove]\n",
        "              else:\n",
        "                  available_indices.remove(random_sample_number)  # Remove the index if it doesn't fit the sequence requirement\n",
        "\n",
        "    x = np.array(x)\n",
        "    y = np.array(y)\n",
        "\n",
        "    # Split data into train and test sets in a 70-30 way\n",
        "    split_index = int(len(x) * 0.7)\n",
        "    x_train, x_test = x[:split_index], x[split_index:]\n",
        "    y_train, y_test = y[:split_index], y[split_index:]\n",
        "\n",
        "    return x_train, y_train, x_test, y_test\n",
        "\n",
        "#downgrade numpy\n",
        "# Using split_array function to split the data\n",
        "x_train, y_train, x_test, y_test = split_array(training_array)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "G9Hd3VBlw9UA"
      },
      "outputs": [],
      "source": [
        "x_train = x_train[:, :, [0,5,6,7]]\n",
        "y_train = y_train[:, :, [1,2,3,4]]\n",
        "x_test = x_test[:,:,[0,5,6,7]]\n",
        "y_test = y_test[:,:,[1,2,3,4]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[2.81000000e+01 2.63000000e+01 2.84000000e+01 2.91000000e+01\n",
            "  2.30000000e+01 8.00661000e+02 9.80000000e+01 1.94000000e+01\n",
            "  1.61443398e+09 8.40248070e-01 5.42202159e-01]\n",
            " [2.81000000e+01 2.63000000e+01 2.85000000e+01 2.94000000e+01\n",
            "  2.29000000e+01 8.00610000e+02 9.80000000e+01 1.94000000e+01\n",
            "  1.61443404e+09 8.40248070e-01 5.42202159e-01]\n",
            " [2.81000000e+01 2.63000000e+01 2.85000000e+01 2.94000000e+01\n",
            "  2.27000000e+01 8.01060000e+02 9.80000000e+01 1.94000000e+01\n",
            "  1.61443410e+09 8.40248070e-01 5.42202159e-01]\n",
            " [2.82000000e+01 2.63000000e+01 2.85000000e+01 2.89000000e+01\n",
            "  2.27000000e+01 8.00515000e+02 9.80000000e+01 1.95000000e+01\n",
            "  1.61443416e+09 8.40248070e-01 5.42202159e-01]\n",
            " [2.81000000e+01 2.63000000e+01 2.87000000e+01 2.91000000e+01\n",
            "  2.26000000e+01 8.00792000e+02 9.80000000e+01 1.95000000e+01\n",
            "  1.61443422e+09 8.40248070e-01 5.42202159e-01]\n",
            " [2.81000000e+01 2.63000000e+01 2.88000000e+01 2.94000000e+01\n",
            "  2.26000000e+01 8.00782000e+02 9.80000000e+01 1.95000000e+01\n",
            "  1.61443428e+09 8.40248070e-01 5.42202159e-01]\n",
            " [2.80000000e+01 2.63000000e+01 2.90000000e+01 2.98000000e+01\n",
            "  2.28000000e+01 8.00957000e+02 9.80000000e+01 1.95000000e+01\n",
            "  1.61443434e+09 8.40248070e-01 5.42202159e-01]\n",
            " [2.80000000e+01 2.63000000e+01 2.90000000e+01 2.95000000e+01\n",
            "  2.29000000e+01 8.01049000e+02 9.80000000e+01 1.95000000e+01\n",
            "  1.61443440e+09 8.40248070e-01 5.42202159e-01]\n",
            " [2.80000000e+01 2.63000000e+01 2.90000000e+01 2.93000000e+01\n",
            "  2.27000000e+01 8.00726000e+02 9.80000000e+01 1.95000000e+01\n",
            "  1.61443446e+09 8.40248070e-01 5.42202159e-01]\n",
            " [2.80000000e+01 2.63000000e+01 2.91000000e+01 2.93000000e+01\n",
            "  2.28000000e+01 8.00931000e+02 9.80000000e+01 1.96000000e+01\n",
            "  1.61443452e+09 8.40248070e-01 5.42202159e-01]\n",
            " [2.80000000e+01 2.63000000e+01 2.91000000e+01 2.94000000e+01\n",
            "  2.28000000e+01 8.00960000e+02 9.80000000e+01 1.96000000e+01\n",
            "  1.61443458e+09 8.40248070e-01 5.42202159e-01]\n",
            " [2.80000000e+01 2.63000000e+01 2.91000000e+01 2.92000000e+01\n",
            "  2.28000000e+01 8.00945000e+02 9.80000000e+01 1.97000000e+01\n",
            "  1.61443464e+09 8.40248070e-01 5.42202159e-01]\n",
            " [2.80000000e+01 2.63000000e+01 2.91000000e+01 2.89000000e+01\n",
            "  2.28000000e+01 8.01153000e+02 9.80000000e+01 1.97000000e+01\n",
            "  1.61443470e+09 8.40248070e-01 5.42202159e-01]\n",
            " [2.80000000e+01 2.63000000e+01 2.94000000e+01 2.92000000e+01\n",
            "  2.28000000e+01 8.01210000e+02 9.80000000e+01 1.97000000e+01\n",
            "  1.61443476e+09 8.40248070e-01 5.42202159e-01]\n",
            " [2.81000000e+01 2.64000000e+01 2.96000000e+01 2.91000000e+01\n",
            "  2.26000000e+01 8.01152000e+02 9.80000000e+01 1.97000000e+01\n",
            "  1.61443482e+09 8.40248070e-01 5.42202159e-01]]\n"
          ]
        }
      ],
      "source": [
        "print(x_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train = x_train[:, :, [0, 5, 6, 7, 8, 9, 10]]  # Including the additional date features\n",
        "y_train = y_train[:, :, [1, 2, 3, 4]]\n",
        "x_test = x_test[:, :, [0, 5, 6, 7, 8, 9, 10]]\n",
        "y_test = y_test[:, :, [1, 2, 3, 4]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "ltu1imsjw9UA",
        "outputId": "49e90b03-1394-46ef-ec02-6462f7adadcb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(36031, 15, 7) (36031, 15, 4) (15442, 15, 7) (15442, 15, 4)\n"
          ]
        }
      ],
      "source": [
        "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "AaLOCPTVw9UA",
        "outputId": "26768657-23bd-476a-ac39-aea558a1c26a"
      },
      "outputs": [],
      "source": [
        "input_layer = Input(shape=(15, 7))\n",
        "\n",
        "# First LSTM layer with dropout and batch normalization\n",
        "lstm1 = LSTM(128, return_sequences=True)(input_layer)\n",
        "dropout1 = Dropout(0.2)(lstm1)\n",
        "norm1 = BatchNormalization()(dropout1)\n",
        "\n",
        "# Second GRU layer with dropout and batch normalization\n",
        "gru1 = GRU(128, return_sequences=True)(norm1)\n",
        "dropout2 = Dropout(0.2)(gru1)\n",
        "norm2 = BatchNormalization()(dropout2)\n",
        "\n",
        "# Residual connection\n",
        "residual = Add()([norm1, norm2])\n",
        "\n",
        "# Third LSTM layer\n",
        "lstm2 = LSTM(128, return_sequences=True)(residual)\n",
        "dropout3 = Dropout(0.2)(lstm2)\n",
        "norm3 = BatchNormalization()(dropout3)\n",
        "\n",
        "# TimeDistributed dense layer for output\n",
        "output_layer = TimeDistributed(Dense(4))(norm3)\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=input_layer, outputs=output_layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "lAI-5zuzw9UA",
        "outputId": "758182e6-e263-4870-8b60-c6fc4baeff28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 27ms/step - loss: 1267.1035 - val_loss: 366.2905\n",
            "Epoch 2/25\n",
            "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 28ms/step - loss: 403.2494 - val_loss: 404.2841\n",
            "Epoch 3/25\n",
            "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 27ms/step - loss: 401.1758 - val_loss: 379.0873\n",
            "Epoch 4/25\n",
            "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 28ms/step - loss: 395.6058 - val_loss: 368.5954\n",
            "Epoch 5/25\n",
            "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 27ms/step - loss: 393.3676 - val_loss: 374.5950\n",
            "Epoch 6/25\n",
            "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 27ms/step - loss: 397.1775 - val_loss: 364.9939\n",
            "Epoch 7/25\n",
            "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 27ms/step - loss: 393.8477 - val_loss: 369.8659\n",
            "Epoch 8/25\n",
            "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 27ms/step - loss: 394.7215 - val_loss: 387.8050\n",
            "Epoch 9/25\n",
            "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 27ms/step - loss: 388.8165 - val_loss: 390.8146\n",
            "Epoch 10/25\n",
            "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 28ms/step - loss: 394.5200 - val_loss: 355.4671\n",
            "Epoch 11/25\n",
            "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 27ms/step - loss: 392.4124 - val_loss: 362.1750\n",
            "Epoch 12/25\n",
            "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 27ms/step - loss: 392.8873 - val_loss: 366.5034\n",
            "Epoch 13/25\n",
            "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 27ms/step - loss: 390.0825 - val_loss: 374.6902\n",
            "Epoch 14/25\n",
            "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 27ms/step - loss: 395.8958 - val_loss: 367.6221\n",
            "Epoch 15/25\n",
            "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 27ms/step - loss: 393.7894 - val_loss: 378.3237\n",
            "Epoch 16/25\n",
            "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 27ms/step - loss: 396.5811 - val_loss: 368.8003\n",
            "Epoch 17/25\n",
            "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 27ms/step - loss: 392.0970 - val_loss: 385.1104\n",
            "Epoch 18/25\n",
            "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 28ms/step - loss: 390.6085 - val_loss: 373.5424\n",
            "Epoch 19/25\n",
            "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 27ms/step - loss: 391.8386 - val_loss: 377.0702\n",
            "Epoch 20/25\n",
            "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 27ms/step - loss: 394.9386 - val_loss: 389.7803\n",
            "Epoch 21/25\n",
            "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 27ms/step - loss: 393.2437 - val_loss: 366.7906\n",
            "Epoch 22/25\n",
            "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 27ms/step - loss: 393.9171 - val_loss: 384.4345\n",
            "Epoch 23/25\n",
            "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 27ms/step - loss: 392.9430 - val_loss: 381.7748\n",
            "Epoch 24/25\n",
            "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 28ms/step - loss: 397.7538 - val_loss: 381.9336\n",
            "Epoch 25/25\n",
            "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 26ms/step - loss: 393.2929 - val_loss: 373.6788\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x1b090015430>"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
        "\n",
        "model.fit(x_train, y_train, epochs=25, batch_size=64, validation_data=(x_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jq9O4KIkw9UB"
      },
      "outputs": [],
      "source": [
        "#model.save('/home/yjain0201/Yash Machine Learning Code/Saved Models/model_64_LSTM_Temporal_by_epoch_all.keras')\n",
        "#loss: 456.2441 - val_loss: 77.4721"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "[[[38.794548 35.85325  35.161613 30.126495]\n",
            "  [38.774982 35.851967 35.08473  30.081663]\n",
            "  [38.68669  35.786854 35.05961  30.040895]\n",
            "  [38.79752  35.9013   35.167812 30.160845]\n",
            "  [38.809643 35.926437 35.178196 30.191174]\n",
            "  [38.712788 35.830353 35.0702   30.122526]\n",
            "  [38.490944 35.594254 34.834232 29.946495]\n",
            "  [38.496834 35.55325  34.83253  29.905128]\n",
            "  [38.758503 35.949917 35.108105 30.129408]\n",
            "  [38.821148 36.092514 35.21436  30.24279 ]\n",
            "  [38.8694   36.090378 35.25922  30.281338]\n",
            "  [39.061184 36.206337 35.421146 30.404522]\n",
            "  [39.163486 36.26862  35.507034 30.468927]\n",
            "  [39.184322 36.281372 35.5246   30.482191]\n",
            "  [39.18954  36.285175 35.529293 30.485832]]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "[[6.69454803 4.2532486  4.86161346 3.02649536]\n",
            " [6.57498245 4.25196686 4.78472824 3.08166313]\n",
            " [6.48669128 4.18685379 4.85960846 2.74089546]\n",
            " [6.59751968 4.30129852 4.86781235 3.0608448 ]\n",
            " [6.50964279 4.32643738 4.97819595 3.09117355]\n",
            " [6.31278763 4.13035278 5.07020187 3.02252617]\n",
            " [5.99094391 3.89425354 4.83423233 3.04649506]\n",
            " [6.0968338  3.85324936 4.83253098 3.00512848]\n",
            " [6.45850296 4.34991684 5.00810471 3.12940788]\n",
            " [6.42114792 4.39251404 5.21435928 3.14279022]\n",
            " [6.46940002 4.29037781 5.15922012 3.18133774]\n",
            " [6.56118393 4.40633698 5.52114639 3.10452194]\n",
            " [6.66348648 4.46861954 5.6070343  3.06892738]\n",
            " [6.68432236 4.58137207 5.52460098 3.18219109]\n",
            " [6.68954086 4.58517532 5.42929306 3.18583221]]\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "input_array = np.array([[33.8, 791.256, 100, 25.3],[33.8, 791.485, 100, 25.3],[33.8, 791.5, 100, 25.3],[33.8, 791.806, 100, 25.3],[33.7, 790.983, 100, 25.4],[33.7, 790.794, 100, 25.4],[33.7, 791.340, 100, 25.4],[33.8, 791.740, 100, 25.4],[33.8, 791.658, 100, 25.4],[33.7, 791.662, 100, 25.4],[33.7, 791.781, 100, 25.4],[33.7, 792.025, 100, 25.4],[33.7, 791.707, 100, 25.4],[33.7, 791.854, 100, 25.4],[33.7, 791.691, 100, 25.4]])\n",
        "dates = pd.to_datetime([\n",
        "    \"11/23/2023 0:00\",\n",
        "    \"11/23/2023 0:01\",\n",
        "    \"11/23/2023 0:02\",\n",
        "    \"11/23/2023 0:03\",\n",
        "    \"11/23/2023 0:04\",\n",
        "    \"11/23/2023 0:05\",\n",
        "    \"11/23/2023 0:06\",\n",
        "    \"11/23/2023 0:07\",\n",
        "    \"11/23/2023 0:08\",\n",
        "    \"11/23/2023 0:09\",\n",
        "    \"11/23/2023 0:10\",\n",
        "    \"11/23/2023 0:11\",\n",
        "    \"11/23/2023 0:12\",\n",
        "    \"11/23/2023 0:13\",\n",
        "    \"11/23/2023 0:14\"\n",
        "])\n",
        "'''\n",
        "input_array = np.array([[46.8, 782.602, 100, 28.9],[47.3, 782.433, 100, 28.8],[47.5, 782.502, 100, 28.8],[47.3, 782.333, 100, 28.6],[47.3, 782.314, 100, 28.6],[47.1, 782.396, 100, 28.5],[46.9, 782.439, 100, 28.5],[46.7, 782.339, 100, 28.5],[46.5, 782.481, 100, 28.5],[46.4, 782.520, 100, 28.4],[46.4, 782.493, 100, 28.4],[46.4, 782.395, 100, 28.4],[46.3, 782.443, 100, 28.4],[46.4, 782.536, 100, 28.4],[28.4,782.560, 100, 28.4]])\n",
        "dates = pd.to_datetime([\n",
        "    \"12/18/2023 19:30\",\n",
        "    \"12/18/2023 19:31\",\n",
        "    \"12/18/2023 19:32\",\n",
        "    \"12/18/2023 19:33\",\n",
        "    \"12/18/2023 19:34\",\n",
        "    \"12/18/2023 19:35\",\n",
        "    \"12/18/2023 19:36\",\n",
        "    \"12/18/2023 19:37\",\n",
        "    \"12/18/2023 19:38\",\n",
        "    \"12/18/2023 19:39\",\n",
        "    \"12/18/2023 19:40\",\n",
        "    \"12/18/2023 19:41\",\n",
        "    \"12/18/2023 19:42\",\n",
        "    \"12/18/2023 19:43\",\n",
        "    \"12/18/2023 19:44\"\n",
        "\n",
        "])\n",
        "\n",
        "# Preprocess dates\n",
        "timestamps = dates.astype('int64') // 10**9  # Convert to seconds since epoch\n",
        "day_of_year = dates.dayofyear\n",
        "day_sin = np.sin(2 * np.pi * day_of_year / 365.25)\n",
        "day_cos = np.cos(2 * np.pi * day_of_year / 365.25)\n",
        "\n",
        "# Append date features to input_array\n",
        "date_features = np.stack([timestamps, day_sin, day_cos], axis=-1)\n",
        "input_array_with_dates = np.concatenate([input_array, date_features], axis=-1)\n",
        "\n",
        "# Reshape the array to (1, 15, 7)\n",
        "input_array_with_dates = input_array_with_dates.reshape(1, 15, 7)\n",
        "\n",
        "# Make a prediction\n",
        "predictions = model.predict(input_array_with_dates)\n",
        "print(predictions)\n",
        "\n",
        "testing = pd.read_csv(r\"C:\\Users\\yjain\\Desktop\\mtwash\\Mt Wash Data\\Test_temporal_model_2.csv\")\n",
        "testing.pop('date')\n",
        "testing.pop('AR43Temperature')\n",
        "testing.pop('AR16Temperature')\n",
        "testing_array = np.array(testing, dtype='float')\n",
        "beeg_boi = []\n",
        "for i in range(0,15):\n",
        "    temp_list = []\n",
        "    for j in range(0,4):\n",
        "        temp_list.append(np.array(model.predict(input_array_with_dates)[0][i][j]) - testing_array[i+15][j])\n",
        "    beeg_boi.append(temp_list)\n",
        "\n",
        "print(np.array(beeg_boi))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[42.9 37.8 35.9 31.6]\n",
            " [42.9 37.7 35.9 31.6]\n",
            " [42.8 37.6 35.8 31.5]\n",
            " [42.8 37.5 35.8 31.3]\n",
            " [42.7 37.4 35.7 31.2]\n",
            " [42.7 37.3 35.6 31.2]\n",
            " [42.7 37.2 35.5 31.1]\n",
            " [42.7 37.1 35.5 31.1]\n",
            " [42.6 37.  35.4 31.1]\n",
            " [42.6 36.9 35.3 31.1]\n",
            " [42.5 36.8 35.2 31.1]\n",
            " [42.4 36.8 35.2 31.1]\n",
            " [42.4 36.8 35.1 31.1]\n",
            " [42.3 36.7 34.9 31. ]\n",
            " [42.3 36.7 34.9 31. ]\n",
            " [42.3 36.6 34.8 31. ]\n",
            " [42.2 36.6 34.9 31. ]\n",
            " [42.2 36.5 34.8 30.9]\n",
            " [42.2 36.5 34.8 31. ]\n",
            " [42.1 36.4 34.7 31. ]\n",
            " [42.  36.4 34.7 31. ]\n",
            " [42.  36.4 34.6 31. ]\n",
            " [41.9 36.3 34.5 30.9]\n",
            " [42.  36.3 34.4 31. ]\n",
            " [41.9 36.3 34.4 30.9]\n",
            " [41.8 36.2 34.4 30.8]\n",
            " [41.8 36.2 34.2 30.8]\n",
            " [41.7 36.  34.1 30.8]\n",
            " [41.7 36.  34.2 30.7]\n",
            " [41.7 36.  34.  30.8]\n",
            " [41.7 36.  34.  30.7]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "[[4.01400681 5.77213898 5.49693222 3.38419342]\n",
            " [5.54850845 6.68187943 6.22107849 3.7665329 ]\n",
            " [6.07183151 7.15361404 6.85879822 4.23166809]\n",
            " [6.12218933 7.17953873 6.94015808 4.17575073]\n",
            " [6.18298569 7.25768051 7.01369553 4.14345551]\n",
            " [6.12086487 7.14908371 6.90431671 4.06801605]\n",
            " [5.92340469 7.01587067 6.87510529 3.98446655]\n",
            " [5.81097565 6.96963425 6.83522034 3.99611816]\n",
            " [5.50130844 6.82200928 6.79601059 3.80740738]\n",
            " [5.42984161 6.69783325 6.6714035  3.81741867]\n",
            " [5.4149353  6.71589737 6.57950363 3.84629364]\n",
            " [5.32963867 6.65528946 6.70314865 3.78480072]\n",
            " [5.34143524 6.79035187 6.72554626 3.72429199]\n",
            " [5.30071335 6.76125336 6.57452469 3.77624969]\n",
            " [3.98918228 5.60431671 5.48767471 2.6986496 ]]\n"
          ]
        }
      ],
      "source": [
        "#inputs = np.array([[33.8, 791.256, 100, 25.3],[33.8, 791.485, 100, 25.3],[33.8, 791.5, 100, 25.3],[33.8, 791.806, 100, 25.3],[33.7, 790.983, 100, 25.4],[33.7, 790.794, 100, 25.4],[33.7, 791.340, 100, 25.4],[33.8, 791.740, 100, 25.4],[33.8, 791.658, 100, 25.4],[33.7, 791.662, 100, 25.4],[33.7, 791.781, 100, 25.4],[33.7, 792.025, 100, 25.4],[33.7, 791.707, 100, 25.4],[33.7, 791.854, 100, 25.4],[33.7, 791.691, 100, 25.4]]).reshape(1,15,4)\n",
        "inputs = np.array([[46.8, 782.602, 100, 28.9],[47.3, 782.433, 100, 28.8],[47.5, 782.502, 100, 28.8],[47.3, 782.333, 100, 28.6],[47.3, 782.314, 100, 28.6],[47.1, 782.396, 100, 28.5],[46.9, 782.439, 100, 28.5],[46.7, 782.339, 100, 28.5],[46.5, 782.481, 100, 28.5],[46.4, 782.520, 100, 28.4],[46.4, 782.493, 100, 28.4],[46.4, 782.395, 100, 28.4],[46.3, 782.443, 100, 28.4],[46.4, 782.536, 100, 28.4],[28.4,782.560, 100, 28.4]]).reshape(1,15,4)\n",
        "testing = pd.read_csv(r\"C:\\Users\\yjain\\Desktop\\mtwash\\Mt Wash Data\\Test_temporal_model.csv\")\n",
        "testing.pop('date')\n",
        "testing.pop('AR43Temperature')\n",
        "testing.pop('AR16Temperature')\n",
        "testing_array = np.array(testing, dtype='float')\n",
        "print(testing_array)\n",
        "#print(model.predict(inputs)[0][0][1])\n",
        "beeg_boi = []\n",
        "for i in range(0,15):\n",
        "    temp_list = []\n",
        "    for j in range(0,4):\n",
        "        temp_list.append(np.array(model.predict(inputs)[0][i][j]) - testing_array[i+15][j])\n",
        "    beeg_boi.append(temp_list)\n",
        "\n",
        "print(np.array(beeg_boi))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save(r\"C:\\Users\\yjain\\Desktop\\mtwash\\RNN_128_with_dates.keras\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
